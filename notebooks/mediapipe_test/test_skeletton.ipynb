{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676c6a0061cc029b",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pose Landmarks Detection with MediaPipe Tasks\n",
    "This notebook shows you how to use MediaPipe Tasks Python API to detect pose landmarks from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5257ca36c3693874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T11:36:35.108322Z",
     "start_time": "2026-01-05T11:36:35.103101Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b40e8fca56ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T11:36:35.150292Z",
     "start_time": "2026-01-05T11:36:35.123858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading of config: 2 videos to process.\n",
      "  -> videos/CarvingSkier.mp4 fertig. 60 Frames mit Pose extrahiert.\n",
      "WARNING: File 'videos/squat_falsch.mp4' not found. Skipping...\n",
      "\n",
      "--- Summary ---\n",
      "Number of successfully processed videos: 1\n",
      "Video: videos/CarvingSkier.mp4 | Label: carving_skier | Data shape: (60, 132)\n"
     ]
    }
   ],
   "source": [
    "def load_video_jobs(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Config file '{filepath}' not found.\")\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    if filepath.endswith('.json'):\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            jobs = json.load(f)\n",
    "            \n",
    "    elif filepath.endswith('.csv'):\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                if row.get('input'): \n",
    "                    jobs.append(row)\n",
    "    else:\n",
    "        raise ValueError(\"Config file not of type .json or .csv.\")\n",
    "        \n",
    "    return jobs\n",
    "\n",
    "MODEL_PATH = 'pose_landmarker.task'\n",
    "\n",
    "POSE_CONNECTIONS = frozenset([\n",
    "    (0, 1), (1, 2), (2, 3), (3, 7), (0, 4), (4, 5), (5, 6), (6, 8), (9, 10),\n",
    "    (11, 12), (11, 13), (13, 15), (15, 17), (15, 19), (15, 21), (17, 19),\n",
    "    (12, 14), (14, 16), (16, 18), (16, 20), (16, 22), (18, 20), (11, 23),\n",
    "    (12, 24), (23, 24), (23, 25), (24, 26), (25, 27), (26, 28), (27, 29),\n",
    "    (28, 30), (29, 31), (30, 32), (27, 31), (28, 32)\n",
    "])\n",
    "\n",
    "def extract_features(landmarks):\n",
    "    \"\"\"\n",
    "    Returns: Array with [x1, y1, z1, vis1, x2, y2, ... ] (Size: 33 * 4 = 132)\n",
    "    \"\"\"\n",
    "    if not landmarks:\n",
    "        return np.zeros(33 * 4)\n",
    "    \n",
    "    features = []\n",
    "    for lm in landmarks:\n",
    "        features.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    pose_landmarks_list = detection_result.pose_landmarks\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "    for idx in range(len(pose_landmarks_list)):\n",
    "        pose_landmarks = pose_landmarks_list[idx]\n",
    "        height, width, _ = annotated_image.shape\n",
    "        \n",
    "        for landmark in pose_landmarks:\n",
    "             cx, cy = int(landmark.x * width), int(landmark.y * height)\n",
    "             cv2.circle(annotated_image, (cx, cy), 5, (0, 255, 0), -1)\n",
    "\n",
    "        for connection in POSE_CONNECTIONS:\n",
    "            start_idx = connection[0]\n",
    "            end_idx = connection[1]\n",
    "            start_point = pose_landmarks[start_idx]\n",
    "            end_point = pose_landmarks[end_idx]\n",
    "            x1, y1 = int(start_point.x * width), int(start_point.y * height)\n",
    "            x2, y2 = int(end_point.x * width), int(end_point.y * height)\n",
    "            cv2.line(annotated_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "    return annotated_image\n",
    "\n",
    "def process_single_video(job_config, detector):\n",
    "    input_path = job_config[\"input\"]\n",
    "    output_path = job_config[\"output\"]\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"WARNING: File '{input_path}' not found. Skipping...\")\n",
    "        return None\n",
    "\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"ERROR: Could not open '{input_path}'.\")\n",
    "        return None\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps == 0: fps = 30\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_data = []\n",
    "    frame_index = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "        timestamp_ms = int((frame_index * 1000) / fps)\n",
    "\n",
    "        detection_result = detector.detect_for_video(mp_image, timestamp_ms)\n",
    "        \n",
    "        current_landmarks = None\n",
    "        if detection_result.pose_landmarks:\n",
    "            current_landmarks = detection_result.pose_landmarks[0]\n",
    "            \n",
    "            feature_vector = extract_features(current_landmarks)\n",
    "            frame_data.append(feature_vector)\n",
    "        else:\n",
    "            # Frames without person detected\n",
    "            # ToDo: how to handle missing data? LSTM prefers nulls or last known value.\n",
    "            pass \n",
    "\n",
    "        annotated_frame = draw_landmarks_on_image(rgb_frame, detection_result)\n",
    "        out.write(cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"  -> {input_path} fertig. {len(frame_data)} Frames mit Pose extrahiert.\")\n",
    "    \n",
    "    return {\n",
    "        \"label\": job_config.get(\"label\", \"unknown\"),\n",
    "        \"features\": np.array(frame_data),\n",
    "        \"source_file\": input_path\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \n",
    "    base_options = python.BaseOptions(model_asset_path=MODEL_PATH)\n",
    "    options = vision.PoseLandmarkerOptions(\n",
    "        base_options=base_options,\n",
    "        output_segmentation_masks=False,\n",
    "        running_mode=vision.RunningMode.VIDEO\n",
    "    )\n",
    "\n",
    "    all_training_data = []\n",
    "\n",
    "    try:\n",
    "        video_jobs = load_video_jobs('video_jobs.json')\n",
    "        print(f\"Loading of config: {len(video_jobs)} videos to process.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading configuration: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with vision.PoseLandmarker.create_from_options(options) as detector:\n",
    "            for job in video_jobs:\n",
    "                result = process_single_video(job, detector)\n",
    "                \n",
    "                if result is not None:\n",
    "                    all_training_data.append(result)\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Critical error in main: {e}\")\n",
    "\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    print(f\"Number of successfully processed videos: {len(all_training_data)}\")\n",
    "    \n",
    "    for entry in all_training_data:\n",
    "        print(f\"Video: {entry['source_file']} | Label: {entry['label']} | Data shape: {entry['features'].shape}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
